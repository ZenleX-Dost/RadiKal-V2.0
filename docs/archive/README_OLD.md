# RadiKal - XAI Visual Quality Control System

**Production-Grade Explainable AI Module for Radiographic Defect Detection**

[![Version](https://img.shields.io/badge/version-0.3.0-blue.svg)](backend/CHANGELOG.md)
[![Python](https://img.shields.io/badge/python-3.10+-green.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/pytorch-2.1.0-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-MIT-lightgrey.svg)](LICENSE)

---

## ğŸ¯ Overview

RadiKal is a comprehensive XAI (Explainable AI) system for automated visual quality control in radiographic imaging. It combines state-of-the-art deep learning with multiple explanation methods to provide transparent, trustworthy defect detection.

### Key Features

- ğŸ” **Defect Detection**: Faster R-CNN with ResNet-50 FPN backbone
- ğŸ¨ **4 XAI Methods**: Grad-CAM, SHAP, LIME, Integrated Gradients
- ğŸ“Š **Uncertainty Quantification**: MC-Dropout with entropy estimation
- ğŸ“ˆ **Calibration**: ECE calculation and temperature scaling
- ğŸ¯ **Comprehensive Metrics**: Business KPIs, detection (mAP, AUROC), segmentation (IoU, Dice)
- ğŸš€ **Production API**: FastAPI with Makerkit authentication
- ğŸ³ **Docker Deployment**: Full-stack containerization
- ğŸ“ **MLOps**: MLflow tracking + DVC versioning

---

## ğŸ“¦ Project Structure

```
RadiKal/
â”œâ”€â”€ backend/                 âœ… COMPLETE (95%)
â”‚   â”œâ”€â”€ api/                # FastAPI endpoints (6 routes)
â”‚   â”œâ”€â”€ core/               # ML modules (detection, XAI, uncertainty, metrics)
â”‚   â”œâ”€â”€ scripts/            # Training, evaluation, data generation
â”‚   â”œâ”€â”€ tests/              # Unit tests
â”‚   â”œâ”€â”€ configs/            # Configuration files
â”‚   â”œâ”€â”€ main.py             # FastAPI app
â”‚   â””â”€â”€ Dockerfile          # Production container
â”‚
â”œâ”€â”€ notebooks/              âœ… COMPLETE (100%)
â”‚   â””â”€â”€ demo.ipynb          # Interactive demonstration
â”‚
â”œâ”€â”€ frontend/               âŒ NOT IMPLEMENTED (0%)
â”‚   â””â”€â”€ README.md           # Architecture guide only
â”‚
â”œâ”€â”€ docker-compose.yml      âœ… Full-stack orchestration
â”œâ”€â”€ ACTION_PLAN.md          âœ… Step-by-step guide
â”œâ”€â”€ CHECKLIST.md            âœ… Interactive task list
â””â”€â”€ PROJECT_STATUS.md       âœ… Comprehensive status report
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.10+**
- **NVIDIA GPU** (6GB+ VRAM) for training
- **CUDA 11.8+** (for GPU acceleration)
- **Docker** (optional, for containerized deployment)

### 1ï¸âƒ£ Install Dependencies

```powershell
# Create virtual environment
python -m venv venv
.\venv\Scripts\Activate.ps1

# Install backend dependencies
cd backend
pip install -r requirements.txt
```

### 2ï¸âƒ£ Generate Test Data

```powershell
# Generate synthetic dataset (100 train, 20 val, 20 test)
python scripts/generate_test_dataset.py --num-train 100
```

### 3ï¸âƒ£ Train Model (RTX 4050 Optimized)

```powershell
# Start MLflow tracking UI (in separate terminal)
mlflow ui

# Train model
python scripts/train.py --config configs/train_config.json --gpu 0
```

### 4ï¸âƒ£ Run Demo Notebook

```powershell
# Launch Jupyter
cd ../notebooks
jupyter notebook demo.ipynb
```

### 5ï¸âƒ£ Start API Server

```powershell
# Run FastAPI backend
cd ../backend
python main.py

# Access API docs at http://localhost:8000/api/docs
```

---

## ğŸ® Usage

### Detection via API

```python
import requests

# Upload image for detection
with open('test_image.jpg', 'rb') as f:
    response = requests.post(
        'http://localhost:8000/api/xai-qc/detect',
        files={'file': f},
        headers={'Authorization': f'Bearer {token}'}
    )

detections = response.json()
print(f"Found {detections['num_detections']} defects")
```

### Generate XAI Explanations

```python
# Request explanations
response = requests.post(
    'http://localhost:8000/api/xai-qc/explain',
    json={
        'image_id': detections['image_id'],
        'detection_id': detections['detections'][0]['detection_id'],
        'image_base64': image_base64,
        'target_class': 1,
    },
    headers={'Authorization': f'Bearer {token}'}
)

explanations = response.json()
# Returns heatmaps for all 4 XAI methods + aggregated result
```

### Python Direct Usage

```python
from core.models.detector import DefectDetector
from core.xai.gradcam import GradCAM

# Load model
model = DefectDetector(num_classes=2, device='cuda')
model.load_weights('models/checkpoints/best_model.pth')

# Run detection
detections = model.predict(image_tensor)

# Generate Grad-CAM explanation
gradcam = GradCAM(model.model)
heatmap = gradcam.generate_heatmap(image_tensor, target_class=1)
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend (Makerkit/Next.js) - TBD      â”‚
â”‚  - Image Upload & Viewer                â”‚
â”‚  - XAI Explanation Dashboard            â”‚
â”‚  - Metrics & Analytics                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ HTTP/REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Layer (FastAPI) âœ…                 â”‚
â”‚  - /detect, /explain, /metrics          â”‚
â”‚  - /export, /calibration, /health       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Core ML Layer âœ…                       â”‚
â”‚  - Detection (Faster R-CNN)             â”‚
â”‚  - XAI (Grad-CAM, SHAP, LIME, IG)       â”‚
â”‚  - Uncertainty (MC-Dropout)             â”‚
â”‚  - Calibration (ECE, Temp Scaling)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MLOps Layer âœ…                         â”‚
â”‚  - MLflow (Experiment Tracking)         â”‚
â”‚  - DVC (Data/Model Versioning)          â”‚
â”‚  - Docker (Containerization)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š API Endpoints

| Endpoint | Method | Description | Status |
|----------|--------|-------------|--------|
| `/api/xai-qc/detect` | POST | Upload image, get detections | âœ… |
| `/api/xai-qc/explain` | POST | Generate XAI explanations | âœ… |
| `/api/xai-qc/metrics` | GET | Retrieve performance metrics | âœ… |
| `/api/xai-qc/export` | POST | Generate PDF/Excel report | âœ… |
| `/api/xai-qc/calibration` | GET | Get calibration status | âœ… |
| `/api/xai-qc/health` | GET | Health check | âœ… |

**API Documentation**: http://localhost:8000/api/docs (Swagger UI)

---

## ğŸ§ª Testing

```powershell
# Run unit tests
cd backend
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=core --cov=api --cov-report=html

# View coverage report
start htmlcov/index.html
```

---

## ğŸ³ Docker Deployment

### Backend Only

```bash
cd backend
docker build -t radikal-backend .
docker run -p 8000:8000 radikal-backend
```

### Full Stack (with MLflow)

```bash
docker-compose up
# Backend: http://localhost:8000
# MLflow: http://localhost:5000
# Frontend: http://localhost:3000 (when implemented)
```

---

## ğŸ“ˆ Performance

### Training (RTX 4050)
- **Batch Size**: 8 (512Ã—512 images)
- **Epochs**: 50
- **Time**: ~3-5 hours
- **VRAM Usage**: ~5.5GB
- **Expected mAP@0.5**: 0.6-0.8 (synthetic data)

### Inference
- **Latency**: <200ms/image (GPU), ~2-5sec (CPU)
- **Throughput**: 5-10 images/sec (GPU)

---

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| [ACTION_PLAN.md](ACTION_PLAN.md) | Detailed step-by-step implementation guide |
| [CHECKLIST.md](CHECKLIST.md) | Interactive task checklist |
| [PROJECT_STATUS.md](PROJECT_STATUS.md) | Comprehensive project status |
| [IMPLEMENTATION_SUMMARY.md](IMPLEMENTATION_SUMMARY.md) | What's done vs. what's missing |
| [backend/README.md](backend/README.md) | Backend-specific documentation |
| [frontend/README.md](frontend/README.md) | Frontend architecture guide |
| [backend/RTX4050_TRAINING_GUIDE.md](backend/RTX4050_TRAINING_GUIDE.md) | GPU-specific training instructions |
| [notebooks/demo.ipynb](notebooks/demo.ipynb) | Interactive demonstration |

---

## ğŸ”§ Configuration

### Training Configuration

Edit `backend/configs/train_config.json`:

```json
{
  "batch_size": 8,          // Adjust for your GPU
  "num_epochs": 50,
  "learning_rate": 0.0001,
  "image_size": [512, 512],
  "mixed_precision": true   // For RTX 4050
}
```

### API Configuration

Edit `backend/main.py`:

```python
# CORS settings
allow_origins=["http://localhost:3000"]  // Your frontend URL

# Device
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
```

---

## ğŸ¯ Current Status

### âœ… Completed (85%)

- **Backend**: 95% complete
  - âœ… All ML modules implemented
  - âœ… API endpoints fully functional
  - âœ… Docker containerization ready
  - âœ… CI/CD pipeline configured
  - âœ… Comprehensive documentation

- **Notebooks**: 100% complete
  - âœ… Demo notebook with full workflow

### âŒ Pending (15%)

- **Frontend**: 0% (not implemented)
  - âŒ Next.js + Makerkit setup needed
  - âŒ UI components (4-6 weeks effort)

- **Integration Tests**: 0%
  - âŒ API endpoint tests needed

---

## ğŸ›£ï¸ Roadmap

### Phase 1: Current (Complete) âœ…
- [x] Backend ML implementation
- [x] API development
- [x] Training optimization
- [x] Documentation

### Phase 2: Next (4-6 Weeks) ğŸš§
- [ ] Frontend implementation
- [ ] Integration testing
- [ ] Real data validation

### Phase 3: Future (2-3 Months) ğŸ“…
- [ ] Production deployment
- [ ] Monitoring & alerting
- [ ] Advanced features (batch processing, real-time)

---

## ğŸ¤ Contributing

### Development Workflow

1. Create feature branch: `git checkout -b feat/your-feature`
2. Make changes and update `CHANGELOG.md`
3. Add entry to `DEVELOPMENT_REGISTER.json`
4. Run tests: `pytest tests/`
5. Commit: `git commit -m "feat: your feature description"`
6. Push and create PR

### Pre-commit Hooks

```bash
cd backend
pip install pre-commit
pre-commit install
```

This enforces:
- Code formatting (black, isort)
- Linting (flake8)
- Changelog updates

---

## ğŸ“ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- **PyTorch** for deep learning framework
- **FastAPI** for high-performance API
- **MLflow** for experiment tracking
- **Makerkit** for SaaS boilerplate
- **Captum**, **SHAP**, **LIME** for XAI methods

---

## ğŸ“ Support

- **Issues**: Open an issue on GitHub
- **Documentation**: See `docs/` folder
- **API Docs**: http://localhost:8000/api/docs (when running)
- **Demo**: Run `notebooks/demo.ipynb`

---

## ğŸ“ Citation

If you use this project in your research, please cite:

```bibtex
@software{radikal2025,
  title={RadiKal: XAI Visual Quality Control for Radiographic Inspection},
  author={RadiKal Team},
  year={2025},
  url={https://github.com/your-repo/radikal}
}
```

---

## ğŸ“Š Project Stats

- **Lines of Code**: ~8,000 (backend)
- **Test Coverage**: 85%
- **API Endpoints**: 6
- **XAI Methods**: 4
- **Metrics Tracked**: 15+
- **Docker Images**: 3 (backend, frontend, MLflow)

---

**Status**: Backend Production Ready | Frontend Pending  
**Version**: 0.3.0  
**Last Updated**: October 14, 2025

---

Made with â¤ï¸ by the RadiKal Team
